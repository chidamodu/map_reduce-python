{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to MapReduce and mrjob\n",
    "In this exercise we will be analyzing a social graph of friends with ```mrjob```. Many of the largest datasets on the web today are graphical in nature (web links, social networks, road/geographic networks, etc.) and often you need to use big data technologies like Hadoop if you wish to analyze them at scale. Today we will perform some basic analysis to find all of a users friends, and from this we will perform [triadic closure](http://en.wikipedia.org/wiki/Triadic_closure) to recommend new friends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count of each word across all the documents\n",
    "from mrjob.job import MRJob\n",
    "from string import punctuation\n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield (word.strip(punctuation).lower(), 1)\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield (word, sum(counts))\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample output:\n",
    "\"norton\"\t1\n",
    "\"not\"\t72\n",
    "\"note\"\t10\n",
    "\"noteworthy\"\t1\n",
    "\"nothing\"\t3\n",
    "\"notice\"\t2\n",
    "\"notreached\"\t1\n",
    "\"novel\"\t1\n",
    "\"november\"\t1\n",
    "\"novices\"\t1\n",
    "\"now\"\t8\n",
    "\"null\"\t14\n",
    "\"num_args\"\t8\n",
    "\"number\"\t6\n",
    "\"numbers\"\t3\n",
    "\"nutrasweet\"\t5\n",
    "\"nutrition\"\t1\n",
    "\"nutshell\"\t1\n",
    "\"ny\"\t2\n",
    "\"nyc\"\t1\n",
    "\"o\"\t4\n",
    "\"o&>o\"\t1\n",
    "\"o'reilly\"\t5\n",
    "\"obese\"\t1\n",
    "\"obesity\"\t1\n",
    "\"object\"\t9\n",
    "\"object-code\"\t1\n",
    "\"oboe.cis.ohio-state.edu\"\t1\n",
    "\"obscured\"\t1\n",
    "\"observation\"\t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to get the word count for each topic\n",
    "# from mrjob.job import MRJob\n",
    "# from string import punctuation\n",
    "import os\n",
    "import json\n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper(self, _, filename):\n",
    "        data=[]\n",
    "        # with open(filename) as f:\n",
    "        #     for line in f:\n",
    "        data.append(json.loads(filename))\n",
    "        #f=json.loads(filename)\n",
    "    #your_dict[k] = v.lstrip()\n",
    "        for topic in data:\n",
    "            for k, v in topic.items():\n",
    "                yield(topic[k].strip(punctuation).lower(), 1)\n",
    "                #yield (topic.strip(punctuation).lower(), 1)\n",
    "    def reducer(self, topic, counts):\n",
    "        yield (topic, sum(counts))\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample output\n",
    "\"mini_20_newsgroups\\/sci.med\\/58892\"\t23\n",
    "\"mini_20_newsgroups\\/sci.med\\/58893\"\t17\n",
    "\"mini_20_newsgroups\\/sci.med\\/58894\"\t21\n",
    "\"mini_20_newsgroups\\/sci.med\\/58895\"\t25\n",
    "\"mini_20_newsgroups\\/sci.med\\/58896\"\t52\n",
    "\"mini_20_newsgroups\\/sci.med\\/58897\"\t121\n",
    "\"mini_20_newsgroups\\/sci.med\\/58898\"\t31\n",
    "\"mini_20_newsgroups\\/sci.med\\/58899\"\t28\n",
    "\"mini_20_newsgroups\\/comp.windows.x\\/66398\"\t45\n",
    "\"mini_20_newsgroups\\/comp.windows.x\\/66399\"\t29\n",
    "\"mini_20_newsgroups\\/rec.motorcycles\\/103117\"\t64\n",
    "\"mini_20_newsgroups\\/rec.motorcycles\\/103118\"\t28\n",
    "\"mini_20_newsgroups\\/rec.motorcycles\\/103119\"\t24\n",
    "\"mini_20_newsgroups\\/sci.med\\/58890\"\t58\n",
    "\"mini_20_newsgroups\\/sci.med\\/58891\"\t69\n",
    "\"mini_20_newsgroups\\/.ds_store\"\t23\n",
    "\"mini_20_newsgroups\\/comp.windows.x\\/66322\"\t1626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # #One of MapReduce's built-in objects is the Counter object, which can be used to\n",
    "# to keep the counts of a **fixed** number of categories that you know **ahead**\n",
    "# of time. They can be particularly useful in debugging. Here's a version of\n",
    "# the simple word count script where we count the number of words that come from\n",
    "# each of the `comp`, `sci`, and `rec` groupings that we are passing\n",
    "# in. Note that here we don't have to do a reduce step, which can save quite a\n",
    "# bit of time!\n",
    "import os\n",
    "from mrjob.job import MRJob\n",
    "from string import punctuation\n",
    "class TotalWordCountByTopic(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        filename = os.environ['map_input_file']\n",
    "        filename_parts = filename.split('/')\n",
    "        grouping_part = filename_parts[1].split('.')\n",
    "\n",
    "        for word in line.split():\n",
    "            self.increment_counter(grouping_part[0], 'word_count', 1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    TotalWordCountByTopic.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample output\n",
    "Counters: 3\n",
    "            comp\n",
    "                word_count=9913\n",
    "            rec\n",
    "                word_count=787\n",
    "            sci\n",
    "                word_count=2972"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# '''The classic MapReduce job: count the frequency of words.'''\n",
    "# One of the biggest bottlenecks in a MapReduce job is the data transfer from the map step to the reduce step. To help speed up the data transfer process, MapReduce has a built-in Combiner, which is effectively a Reducer that the map step uses to reduce the data locally (i.e. on that Mapper) before it gets passsed on to the reduce step. This saves some time by lessoning the amount of data that has to be transferred from the map step to the reduce step. Here's a version of the simple word count script that uses a Combiner to get a word count locally on each Mapper before the data is transferred to the Reducer. \n",
    "\n",
    "from mrjob.job import MRJob\n",
    "from string import punctuation\n",
    "class MRWordFreqCount(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            yield (word.strip(punctuation).lower(), 1)\n",
    "    def combiner(self, word, counts):\n",
    "        yield (word, sum(counts))\n",
    "\n",
    "    def reducer(self, word, counts):\n",
    "        yield (word, sum(counts))\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #Write a MapReduce job which returns a list of every user's friends.\n",
    "# from mrjob.job import MRJob\n",
    "# from string import punctuation\n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        q1, q2 = line.split(' ')\n",
    "        yield(q1, q2)\n",
    "        yield(q2, q1)\n",
    "    def reducer(self, n, counts):\n",
    "        #result=[]\n",
    "        yield (n, list(counts))\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample output\n",
    "    0   [1, 2, 5]\n",
    "    1   [0, 3, 4]\n",
    "    2   [0, 3, 4]\n",
    "    3   [1, 2, 4]\n",
    "    4   [1, 2, 3, 5]\n",
    "    5   [0, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get Friend Suggestions\n",
    "# We'd like to give a friend suggestion for each user (if we have a suggestion to give).\n",
    "# Write an additional mapper and reducer that will choose for each user the other user which has the most friends in common with them.\n",
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from itertools import combinations\n",
    "class MRWordFreqCount(MRJob):\n",
    "    def mapper1(self, _, line):\n",
    "        q1, q2 = line.split(' ')\n",
    "        yield(q1, q2)\n",
    "        yield(q2, q1)\n",
    "    def reducer1(self, n, counts):\n",
    "        #result=[]\n",
    "        yield (n, list(counts))\n",
    "    def mapper_second(self, users, friends):\n",
    "        # value=self.increment_counter('num', 'val', 1)\n",
    "        for a, b in combinations(friends, 2):\n",
    "            yield (a,b), 1\n",
    "        for f in friends:\n",
    "            yield (users, f), 0\n",
    "        # v = list(counts)\n",
    "        # self.increment_counter('n', 'v', 1)\n",
    "        # yield _, value\n",
    "    def reducer_second(self, com, flag):\n",
    "        c=0\n",
    "        for fl in flag:\n",
    "            if fl==0:\n",
    "                return\n",
    "            c += fl\n",
    "        #result=[]\n",
    "        yield (com, c)\n",
    "    def mapper_third(self, com, c):\n",
    "        u1, u2=com\n",
    "        yield u1, (u2, c)\n",
    "        yield u2, (u1, c)\n",
    "    def reducer_third(self, ui, co):\n",
    "        yield ui, max(co, key=lambda x: x[1])[0]\n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.mapper1,reducer=self.reducer1), MRStep(mapper=self.mapper_second,reducer=self.reducer_second), MRStep(mapper=self.mapper_third,reducer=self.reducer_third)]\n",
    "if __name__ == '__main__':\n",
    "    MRWordFreqCount.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample output\n",
    "    0   4\n",
    "    1   2\n",
    "    2   1\n",
    "    3   0\n",
    "    4   0\n",
    "    5   1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
